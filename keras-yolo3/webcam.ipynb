{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-18-ef501bbb59f7>, line 48)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-18-ef501bbb59f7>\"\u001b[1;36m, line \u001b[1;32m48\u001b[0m\n\u001b[1;33m    break\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import cv2\n",
    "from utils.utils import get_yolo_boxes, makedirs\n",
    "from utils.bbox import draw_boxes\n",
    "from keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def _main_(args):\n",
    "    config_path  = args.conf\n",
    "    input_path   = args.input\n",
    "    output_path  = args.output\n",
    "\n",
    "    with open(config_path) as config_buffer:    \n",
    "        config = json.load(config_buffer)\n",
    "\n",
    "    makedirs(output_path)\n",
    "\n",
    "    ###############################\n",
    "    #   Set some parameter\n",
    "    ###############################       \n",
    "#     net_h, net_w = 608, 608 # a multiple of 32, the smaller the faster\n",
    "    net_h, net_w = config['model']['min_input_size'], config['model']['max_input_size'] # a multiple of 32, the smaller the faster\n",
    "    obj_thresh, nms_thresh = 0.5, 0.45\n",
    "\n",
    "    ###############################\n",
    "    #   Load the model\n",
    "    ###############################\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = config['train']['gpus']\n",
    "    infer_model = load_model(config['train']['saved_weights_name'])\n",
    "\n",
    "    ###############################\n",
    "    #   Predict bounding boxes \n",
    "    ###############################\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while(1):\n",
    "    # get a frame\n",
    "        ret, frame = cap.read()\n",
    "    # show a frame\n",
    "        cv2.imshow(\"capture\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.imwrite(\"keras-yolo3/fangjian2.jpeg\", frame)\n",
    "        break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "        image = cv2.imread(image_path)   #########################\n",
    "    \n",
    "        # predict the bounding boxes\n",
    "        boxes = get_yolo_boxes(infer_model, [image], net_h, net_w, anchors, obj_thresh, nms_thresh)[0]\n",
    "\n",
    "    # draw bounding boxes on the image using labels\n",
    "        draw_boxes(image, boxes, labels, obj_thresh) \n",
    "\n",
    "    # write the image with bounding boxes to file\n",
    "        output_img_path = output_path + image_path.split('/')[-1]\n",
    "        cv2.imwrite(output_img_path, np.uint8(image))\n",
    "        img = cv2.imread(output_img_path)[:,:,::-1]\n",
    "        plt.imshow(img)     \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"---------------------------------------------------\")    \n",
    " #   raise ValueError('A very specific bad thing happened.')\n",
    "    \n",
    "    \n",
    "    \n",
    "    if 'webcam' in input_path: # do detection on the first webcam\n",
    "        video_reader = cv2.VideoCapture(0)\n",
    "\n",
    "        # the main loop\n",
    "        batch_size  = 1\n",
    "        images      = []\n",
    "        while True:\n",
    "            ret_val, image = video_reader.read()\n",
    "            if ret_val == True: images += [image]\n",
    "\n",
    "            if (len(images)==batch_size) or (ret_val==False and len(images)>0):\n",
    "                batch_boxes = get_yolo_boxes(infer_model, images, net_h, net_w, config['model']['anchors'], obj_thresh, nms_thresh)\n",
    "\n",
    "                for i in range(len(images)):\n",
    "                    draw_boxes(images[i], batch_boxes[i], config['model']['labels'], obj_thresh) \n",
    "                    cv2.imshow('video with bboxes', images[i])\n",
    "                images = []\n",
    "            if cv2.waitKey(1) == 27: \n",
    "                break  # esc to quit\n",
    "        cv2.destroyAllWindows()        \n",
    "    elif input_path[-4:] == '.mp4': # do detection on a video  \n",
    "        print(\".mp4\")\n",
    "        video_out = output_path + input_path.split('/')[-1]\n",
    "        video_reader = cv2.VideoCapture(input_path)\n",
    "        print(\".mp4 end\")\n",
    "        nb_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        frame_h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        frame_w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "        video_writer = cv2.VideoWriter(video_out,\n",
    "                               cv2.VideoWriter_fourcc(*'MPEG'), \n",
    "                               50.0, \n",
    "                               (frame_w, frame_h))\n",
    "        # the main loop\n",
    "        batch_size  = 1\n",
    "        images      = []\n",
    "        start_point = 0 #%\n",
    "        show_window = False\n",
    "        for i in tqdm(range(nb_frames)):\n",
    "            _, image = video_reader.read()\n",
    "            if image is None:\n",
    "                continue\n",
    "            print(image.shape)\n",
    "            if (float(i+1)/nb_frames) > start_point/100.:\n",
    "                images += [image]\n",
    "\n",
    "                if (i%batch_size == 0) or (i == (nb_frames-1) and len(images) > 0):\n",
    "                    # predict the bounding boxes\n",
    "                    batch_boxes = get_yolo_boxes(infer_model, images, net_h, net_w, config['model']['anchors'], obj_thresh, nms_thresh)\n",
    "\n",
    "                    for i in range(len(images)):\n",
    "                        # draw bounding boxes on the image using labels\n",
    "                        draw_boxes(images[i], batch_boxes[i], config['model']['labels'], obj_thresh)   \n",
    "\n",
    "                        # show the video with detection bounding boxes          \n",
    "                        if show_window: cv2.imshow('video with bboxes', images[i])  \n",
    "\n",
    "                        # write result to the output video\n",
    "                        video_writer.write(images[i]) \n",
    "                    images = []\n",
    "                if show_window and cv2.waitKey(1) == 27: break  # esc to quit\n",
    "\n",
    "        if show_window: cv2.destroyAllWindows()\n",
    "        video_reader.release()\n",
    "        video_writer.release()       \n",
    "    elif 1==2:\n",
    "    \n",
    "#     image = cv2.imread(image_path)   #########################\n",
    "    \n",
    "        # predict the bounding boxes\n",
    "        boxes = get_yolo_boxes(infer_model, [image], net_h, net_w, anchors, obj_thresh, nms_thresh)[0]\n",
    "\n",
    "    # draw bounding boxes on the image using labels\n",
    "        draw_boxes(image, boxes, labels, obj_thresh) \n",
    "\n",
    "    # write the image with bounding boxes to file\n",
    "        output_img_path = output_path + image_path.split('/')[-1]\n",
    "        cv2.imwrite(output_img_path, np.uint8(image))\n",
    "        img = cv2.imread(output_img_path)[:,:,::-1]\n",
    "        plt.imshow(img)    \n",
    "    else: # do detection on an image or a set of images\n",
    "        image_paths = []\n",
    "\n",
    "        if os.path.isdir(input_path): \n",
    "            for inp_file in os.listdir(input_path):\n",
    "                image_paths += [input_path + inp_file]\n",
    "        else:\n",
    "            image_paths += [input_path]\n",
    "\n",
    "        image_paths = [inp_file for inp_file in image_paths if (inp_file[-4:] in ['.jpg','.JPG', '.png', '.JPEG'])]\n",
    "\n",
    "        # the main loop\n",
    "        for image_path in image_paths:\n",
    "            image = cv2.imread(image_path)\n",
    "            print(image_path)\n",
    "\n",
    "            # predict the bounding boxes\n",
    "            boxes = get_yolo_boxes(infer_model, [image], net_h, net_w, config['model']['anchors'], obj_thresh, nms_thresh)[0]\n",
    "\n",
    "            # draw bounding boxes on the image using labels\n",
    "            draw_boxes(image, boxes, config['model']['labels'], obj_thresh) \n",
    "     \n",
    "            # write the image with bounding boxes to file\n",
    "            cv2.imwrite(output_path + image_path.split('/')[-1], np.uint8(image))         \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    argparser = argparse.ArgumentParser(description='Predict with a trained yolo model')\n",
    "    argparser.add_argument('-c', '--conf', help='path to configuration file')\n",
    "    argparser.add_argument('-i', '--input', help='path to an image, a directory of images, a video, or webcam')    \n",
    "    argparser.add_argument('-o', '--output', default='output/', help='path to output directory')   \n",
    "    \n",
    "    args = argparser.parse_args()\n",
    "    _main_(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
