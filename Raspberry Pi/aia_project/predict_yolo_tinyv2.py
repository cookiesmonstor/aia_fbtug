{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright(c) 2017 Intel Corporation. \n",
    "# License: MIT See LICENSE file in root directory.\n",
    "\n",
    "from mvnc import mvncapi as mvnc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "IMAGE_FROM_DISK = \"/home/pi/ncappzoo/data/images/nps_chair.png\"\n",
    "GRAPH_PATH = \"./tiny_yolo_v2.graph\"\n",
    "DETECTION_THRESHOLD = 0.40\n",
    "IOU_THRESHOLD = 0.30\n",
    "\n",
    "label_name = {0: \"bg\", 1: \"aeroplane\", 2: \"bicycle\", 3: \"bird\", 4: \"boat\", 5: \"bottle\", 6: \"bus\", 7: \"car\", 8: \"cat\",\n",
    "              9: \"chair\", 10: \"cow\", 11: \"diningtable\", 12: \"dog\", 13: \"horse\", 14: \"motorbike\", 15: \"person\",\n",
    "              16: \"pottedplant\", 17: \"sheep\", 18: \"sofa\", 19: \"train\", 20: \"tvmonitor\"}\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(x * -1.0))\n",
    "\n",
    "\n",
    "def calculate_overlap(x1, w1, x2, w2):\n",
    "    box1_coordinate = max(x1 - w1 / 2.0, x2 - w2 / 2.0)\n",
    "    box2_coordinate = min(x1 + w1 / 2.0, x2 + w2 / 2.0)\n",
    "    overlap = box2_coordinate - box1_coordinate\n",
    "    return overlap\n",
    "\n",
    "\n",
    "def calculate_iou(box, truth):\n",
    "    # calculate the iou intersection over union by first calculating the overlapping height and width\n",
    "    width_overlap = calculate_overlap(box[0], box[2], truth[0], truth[2])\n",
    "    height_overlap = calculate_overlap(box[1], box[3], truth[1], truth[3])\n",
    "    # no overlap\n",
    "    if width_overlap < 0 or height_overlap < 0:\n",
    "        return 0\n",
    "\n",
    "    intersection_area = width_overlap * height_overlap\n",
    "    union_area = box[2] * box[3] + truth[2] * truth[3] - intersection_area\n",
    "    iou = intersection_area / union_area\n",
    "    return iou\n",
    "\n",
    "\n",
    "def apply_nms(boxes):\n",
    "    # sort the boxes by score in descending order\n",
    "    sorted_boxes = sorted(boxes, key=lambda d: d[7])[::-1]\n",
    "    high_iou_objs = dict()\n",
    "    # compare the iou for each of the detected objects\n",
    "    for current_object in range(len(sorted_boxes)):\n",
    "        if current_object in high_iou_objs:\n",
    "            continue\n",
    "\n",
    "        truth = sorted_boxes[current_object]\n",
    "        for next_object in range(current_object + 1, len(sorted_boxes)):\n",
    "            if next_object in high_iou_objs:\n",
    "                continue\n",
    "            box = sorted_boxes[next_object]\n",
    "            iou = calculate_iou(box, truth)\n",
    "            if iou >= IOU_THRESHOLD:\n",
    "                high_iou_objs[next_object] = 1\n",
    "\n",
    "    # filter and sort detected items\n",
    "    filtered_result = list()\n",
    "    for current_object in range(len(sorted_boxes)):\n",
    "        if current_object not in high_iou_objs:\n",
    "            filtered_result.append(sorted_boxes[current_object])\n",
    "    return filtered_result\n",
    "\n",
    "\n",
    "def post_processing(output, original_img):\n",
    "\n",
    "    num_classes = 20\n",
    "    num_grids = 13\n",
    "    num_anchor_boxes = 5\n",
    "    original_results = output.astype(np.float32)   \n",
    "\n",
    "    # Tiny Yolo V2 uses a 13 x 13 grid with 5 anchor boxes for each grid cell.\n",
    "    # This specific model was trained with the VOC Pascal data set and is comprised of 20 classes\n",
    "\n",
    "    original_results = np.reshape(original_results, (13, 13, 125))\n",
    "\n",
    "    # The 125 results need to be re-organized into 5 chunks of 25 values\n",
    "    # 20 classes + 1 score + 4 coordinates = 25 values\n",
    "    # 25 values for each of the 5 anchor bounding boxes = 125 values\n",
    "    reordered_results = np.zeros((13 * 13, 5, 25))\n",
    "\n",
    "    index = 0\n",
    "    for row in range( num_grids ):\n",
    "        for col in range( num_grids ):\n",
    "            for b_box_voltron in range(125):\n",
    "                b_box = row * num_grids + col\n",
    "                b_box_num = int(b_box_voltron / 25)\n",
    "                b_box_info = b_box_voltron % 25\n",
    "                reordered_results[b_box][b_box_num][b_box_info] = original_results[row][col][b_box_voltron]\n",
    "\n",
    "    # shapes for the 5 Tiny Yolo v2 bounding boxes\n",
    "    anchor_boxes = [1.08,1.19, 3.42,4.41, 6.63,11.38, 9.42,5.11, 16.62,10.52]\n",
    "\n",
    "    boxes = list()\n",
    "    # iterate through the grids and anchor boxes and filter out all scores which do not exceed the DETECTION_THRESHOLD\n",
    "    for row in range(num_grids):\n",
    "        for col in range(num_grids):\n",
    "            for anchor_box_num in range(num_anchor_boxes):\n",
    "                box = list()\n",
    "                class_list = list()\n",
    "                current_score_total = 0\n",
    "                # calculate the coordinates for the current anchor box\n",
    "                box_x = (col + sigmoid(reordered_results[row * 13 + col][anchor_box_num][0])) / 13.0\n",
    "                box_y = (row + sigmoid(reordered_results[row * 13 + col][anchor_box_num][1])) / 13.0\n",
    "                box_w = (np.exp(reordered_results[row * 13 + col][anchor_box_num][2]) *\n",
    "                         anchor_boxes[2 * anchor_box_num]) / 13.0\n",
    "                box_h = (np.exp(reordered_results[row * 13 + col][anchor_box_num][3]) *\n",
    "                         anchor_boxes[2 * anchor_box_num + 1]) / 13.0\n",
    "                \n",
    "                # find the class with the highest score\n",
    "                for class_enum in range(num_classes):\n",
    "                    class_list.append(reordered_results[row * 13 + col][anchor_box_num][5 + class_enum])\n",
    "\n",
    "                # perform a Softmax on the classes\n",
    "                highest_class_score = max(class_list)\n",
    "                for current_class in range(len(class_list)):\n",
    "                    class_list[current_class] = np.exp(class_list[current_class] - highest_class_score)\n",
    "\n",
    "                current_score_total = sum(class_list)\n",
    "                for current_class in range(len(class_list)):\n",
    "                    class_list[current_class] = class_list[current_class] * 1.0 / current_score_total\n",
    "\n",
    "                # probability that the current anchor box contains an item\n",
    "                object_confidence = sigmoid(reordered_results[row * 13 + col][anchor_box_num][4])\n",
    "                # highest class score detected for the object in the current anchor box\n",
    "                highest_class_score = max(class_list)\n",
    "                # index of the class with the highest score\n",
    "                class_w_highest_score = class_list.index(max(class_list)) + 1\n",
    "                # the final score for the detected object\n",
    "                final_object_score = object_confidence * highest_class_score\n",
    "\n",
    "                box.append(box_x)\n",
    "                box.append(box_y)\n",
    "                box.append(box_w)\n",
    "                box.append(box_h)\n",
    "                box.append(class_w_highest_score)\n",
    "                box.append(object_confidence)\n",
    "                box.append(highest_class_score)\n",
    "                box.append(final_object_score)\n",
    "\n",
    "                # filter out all detected objects with a score less than the threshold\n",
    "                if final_object_score > DETECTION_THRESHOLD:\n",
    "                    boxes.append(box)\n",
    "\n",
    "    # gets rid of all duplicate boxes using non-maximal suppression\n",
    "    results = apply_nms(boxes)\n",
    "\n",
    "    image_width = original_img.shape[1]\n",
    "    image_height = original_img.shape[0]\n",
    "\n",
    "    # calculate the actual box coordinates in relation to the input image\n",
    "    for box in results:\n",
    "        box_xmin = (box[0] - box[2] / 2.0) * image_width\n",
    "        box_xmax = (box[0] + box[2] / 2.0) * image_width\n",
    "        box_ymin = (box[1] - box[3] / 2.0) * image_height\n",
    "        box_ymax = (box[1] + box[3] / 2.0) * image_height\n",
    "        # ensure the box is not drawn out of the window resolution\n",
    "        if box_xmin < 0:\n",
    "            box_xmin = 0\n",
    "        if box_xmax > image_width:\n",
    "            box_xmax = image_width\n",
    "        if box_ymin < 0:\n",
    "            box_ymin = 0\n",
    "        if box_ymax > image_height:\n",
    "            box_ymax = image_height\n",
    "\n",
    "        print (label_name[box[4]], box_xmin, box_ymin, box_xmax, box_ymax)\n",
    "\n",
    "        # label shape and colorization\n",
    "        label_text = label_name[box[4]] + \" \" + str(\"{0:.2f}\".format(box[5]*box[6]))\n",
    "        label_background_color = (70, 120, 70) # grayish green background for text\n",
    "        label_text_color = (255, 255, 255)   # white text\n",
    "\n",
    "        label_size = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n",
    "        label_left = int(box_xmin)\n",
    "        label_top = int(box_ymin) - label_size[1]\n",
    "        label_right = label_left + label_size[0]\n",
    "        label_bottom = label_top + label_size[1]\n",
    "\n",
    "        # set up the colored rectangle background for text\n",
    "        cv2.rectangle(original_img, (label_left - 1, label_top - 5),(label_right + 1, label_bottom + 1),\n",
    "                      label_background_color, -1)\n",
    "        # set up text\n",
    "        cv2.putText(original_img, label_text, (int(box_xmin), int(box_ymin - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    label_text_color, 1)\n",
    "        # set up the rectangle around the object\n",
    "        cv2.rectangle(original_img, (int(box_xmin), int(box_ymin)), (int(box_xmax), int(box_ymax)), (0, 255, 0), 2)\n",
    "\n",
    "    # display all items overlayed in the render window\n",
    "    cv2.imshow('Tiny Yolo V2', original_img)\n",
    "    cv2.waitKey()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # read an image in bgr format\n",
    "    img = cv2.imread(IMAGE_FROM_DISK)\n",
    "    original_img = img\n",
    "\n",
    "    # bgr input scaling\n",
    "    img = np.divide(img, 255.0)\n",
    "    resized_img = cv2.resize(img, (416, 416), cv2.INTER_LINEAR)\n",
    "\n",
    "    # transpose the image to rgb\n",
    "    resized_img = resized_img[:, :, ::-1]\n",
    "    resized_img = resized_img.astype(np.float32)\n",
    "\n",
    "    mvnc.global_set_option(mvnc.GlobalOption.RW_LOG_LEVEL, 2)\n",
    "\n",
    "    # enumerate all devices\n",
    "    devices = mvnc.enumerate_devices()\n",
    "    if len(devices) == 0:\n",
    "        print('No devices found')\n",
    "        quit()\n",
    "\n",
    "    # use the first device found\n",
    "    device = mvnc.Device(devices[0])\n",
    "    # open the device\n",
    "    device.open()\n",
    "\n",
    "    # load the model from the disk\n",
    "    with open(GRAPH_PATH, mode='rb') as f:\n",
    "        graph_in_memory = f.read()\n",
    "\n",
    "    graph = mvnc.Graph(GRAPH_PATH)\n",
    "\n",
    "    # create the input and output fifos\n",
    "    fifo_in, fifo_out = graph.allocate_with_fifos(device, graph_in_memory)\n",
    "\n",
    "    # make an inference\n",
    "    graph.queue_inference_with_fifo_elem(fifo_in, fifo_out, resized_img, 'user object')\n",
    "    # get the result\n",
    "    output, userobj = fifo_out.read_elem()\n",
    "\n",
    "    # Tiny Yolo V2 requires post processing to filter out duplicate objects and low score objects\n",
    "    # After post processing, the app will display the image and any detected objects\n",
    "    post_processing(output, original_img)\n",
    "\n",
    "    # clean up\n",
    "    fifo_in.destroy()\n",
    "    fifo_out.destroy()\n",
    "    graph.destroy()\n",
    "    device.close()\n",
    "    device.destroy()\n",
    "    print(\"Finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
