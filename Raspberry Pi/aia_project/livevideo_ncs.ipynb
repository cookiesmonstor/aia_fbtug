{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import argparse\n",
    "import mvnc.mvncapi as mvnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable to store commandline arguments\n",
    "ARGS = None\n",
    "\n",
    "# OpenCV object for video capture\n",
    "camera = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Define necessary functions for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(boxA, boxB):\n",
    "    # Determine the coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # Compute the area of intersection\n",
    "    intersection_area = (xB - xA + 1) * (yB - yA + 1)\n",
    "\n",
    "    # Compute the area of both rectangles\n",
    "    boxA_area = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxB_area = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    # Compute the IOU\n",
    "    iou = intersection_area / float(boxA_area + boxB_area - intersection_area)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def non_maximal_suppression(thresholded_predictions, iou_threshold):\n",
    "    nms_predictions = []\n",
    "    nms_predictions.append(thresholded_predictions[0])\n",
    "\n",
    "    i = 1\n",
    "    while i < len(thresholded_predictions):\n",
    "        n_boxes_to_check = len(nms_predictions)\n",
    "        to_delete = False\n",
    "\n",
    "        j = 0\n",
    "        while j < n_boxes_to_check:\n",
    "            curr_iou = iou(\n",
    "                thresholded_predictions[i][0], nms_predictions[j][0])\n",
    "            if(curr_iou > iou_threshold):\n",
    "                to_delete = True\n",
    "            j = j + 1\n",
    "\n",
    "        if to_delete == False:\n",
    "            nms_predictions.append(thresholded_predictions[i])\n",
    "        i = i + 1\n",
    "\n",
    "    return nms_predictions\n",
    "\n",
    "def read_labels():\n",
    "    classes = []\n",
    "    with open('labels.txt', 'r') as file:\n",
    "        lines = file.read().splitlines()\n",
    "        for line in lines:\n",
    "            classes.append(line)\n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Open the enumerated device and get a handle to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_ncs_device():\n",
    "    # Look for enumerated NCS device(s); quit program if none found.\n",
    "    devices = mvnc.enumerate_devices()\n",
    "    if len(devices) == 0:\n",
    "        print(\"No devices found\")\n",
    "        quit()\n",
    "\n",
    "    # Get a handle to the first enumerated device and open it\n",
    "    device = mvnc.Device(devices[0])\n",
    "    device.open()\n",
    "\n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load a graph file onto the NCS device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(device):\n",
    "    # Read the graph file into a buffer\n",
    "    with open(ARGS.graph, mode='rb') as f:\n",
    "        graph_buffer = f.read()\n",
    "\n",
    "    # Initialize Graph object\n",
    "    graph = mvnc.Graph('graph')\n",
    "\n",
    "    # Allocate the graph to the device and create input/output Fifos with default options in one call\n",
    "    input_fifo, output_fifo = graph.allocate_with_fifos(device, graph_buffer)\n",
    "\n",
    "    return graph, input_fifo, output_fifo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Pre-process the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(frame):\n",
    "    # Resize image [Image size if defined by choosen network, during training]\n",
    "    resized_image = cv2.resize(frame, tuple(\n",
    "        ARGS.dim), interpolation=cv2.INTER_CUBIC)\n",
    "    image_data = np.array(resized_image, dtype='f')\n",
    "\n",
    "    # Normalization [0,255] -> [0,1]\n",
    "    image_data /= 255.\n",
    "\n",
    "    # Add batch dimension\n",
    "    image_array = np.expand_dims(image_data, 0)\n",
    "\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Read & print inference results from the NCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_image(graph, input_fifo, output_fifo, img, frame):\n",
    "    # Write the image to the input queue and queue the inference in one call\n",
    "    graph.queue_inference_with_fifo_elem(input_fifo, output_fifo, img, None)\n",
    "\n",
    "    # Get the results from the output queue\n",
    "    output, userobj = output_fifo.read_elem()\n",
    "\n",
    "    # Get execution time\n",
    "    inference_time = graph.get_option(mvnc.GraphOption.RO_TIME_TAKEN)\n",
    "\n",
    "    predictions = output\n",
    "    score_threshold = 0.45\n",
    "    iou_threshold = 0.25\n",
    "\n",
    "    input_width = frame.shape[1]\n",
    "    input_height = frame.shape[0]\n",
    "\n",
    "    w_scale = input_width / ARGS.dim[0]\n",
    "    h_scale = input_height / ARGS.dim[1]\n",
    "\n",
    "    input_image = frame\n",
    "\n",
    "    n_classes = 80\n",
    "    n_grid_cells = 13\n",
    "    n_b_boxes = 5\n",
    "    n_b_box_coord = 4\n",
    "\n",
    "    classes = read_labels()\n",
    "\n",
    "    # Pre-computed YOLOv2 shapes of the k=5 B-Boxes\n",
    "    anchors = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843,\n",
    "               5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "\n",
    "    thresholded_predictions = []\n",
    "\n",
    "    # IMPORTANT: reshape to have shape = [13 x 13 x (5 B-Boxes) x (4 Coords + 1 Obj score + 20 Class scores)]\n",
    "    predictions = np.reshape(predictions, (13, 13, 5, 85))\n",
    "\n",
    "    # IMPORTANT: Compute the coordinates and score of the B-Boxes by considering the parametrization of YOLOv2\n",
    "    for row in range(n_grid_cells):\n",
    "        for col in range(n_grid_cells):\n",
    "            for b in range(n_b_boxes):\n",
    "\n",
    "                tx, ty, tw, th, tc = predictions[row, col, b, :5]\n",
    "\n",
    "                # IMPORTANT: (416 img size) / (13 grid cells) = 32!\n",
    "                center_x = (float(col) + sigmoid(tx)) * 32.0\n",
    "                center_y = (float(row) + sigmoid(ty)) * 32.0\n",
    "\n",
    "                roi_w = np.exp(tw) * anchors[2 * b + 0] * 32.0\n",
    "                roi_h = np.exp(th) * anchors[2 * b + 1] * 32.0\n",
    "\n",
    "                final_confidence = sigmoid(tc)\n",
    "\n",
    "                # Find best class\n",
    "                class_predictions = predictions[row, col, b, 5:]\n",
    "                class_predictions = softmax(class_predictions)\n",
    "\n",
    "                class_predictions = tuple(class_predictions)\n",
    "                best_class = class_predictions.index(max(class_predictions))\n",
    "                best_class_score = class_predictions[best_class]\n",
    "\n",
    "                # Flip the coordinates on both axes\n",
    "                left = int(center_x - (roi_w / 2.))\n",
    "                right = int(center_x + (roi_w / 2.))\n",
    "                top = int(center_y - (roi_h / 2.))\n",
    "                bottom = int(center_y + (roi_h / 2.))\n",
    "\n",
    "                if((final_confidence * best_class_score) > score_threshold):\n",
    "                    thresholded_predictions.append(\n",
    "                        [[left, top, right, bottom], final_confidence * best_class_score, classes[best_class]])\n",
    "\n",
    "    # Sort the B-boxes by their final score\n",
    "    thresholded_predictions.sort(key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    # Non maximal suppression\n",
    "    nms_predictions = []\n",
    "    if(len(thresholded_predictions) > 0):\n",
    "        nms_predictions = non_maximal_suppression(\n",
    "            thresholded_predictions, iou_threshold)\n",
    "\n",
    "    # Draw final B-Boxes and label on input image\n",
    "    biggest_object = (0, ())\n",
    "    for i in range(len(nms_predictions)):\n",
    "        xmin = int(nms_predictions[i][0][0] * w_scale)\n",
    "        ymin = int(nms_predictions[i][0][1] * h_scale)\n",
    "        xmax = int(nms_predictions[i][0][2] * w_scale)\n",
    "        ymax = int(nms_predictions[i][0][3] * h_scale)\n",
    "\n",
    "        box_width = xmax - xmin\n",
    "        box_height = ymax - ymin\n",
    "\n",
    "        centroid = (int(box_width / 2 + xmin), int(box_height / 2 + ymin))\n",
    "\n",
    "        confidence = '{:.2f}%'.format(nms_predictions[i][1] * 100)\n",
    "        best_class_name = nms_predictions[i][2]\n",
    "\n",
    "        print('class: ' + best_class_name + ', confidence: ' +\n",
    "              str(confidence) + ', took: ' + str(np.sum(inference_time)))\n",
    "\n",
    "        # Put a class rectangle with B-Box coordinates and a class label on the image\n",
    "        input_image = cv2.circle(input_image, centroid, 5, (0, 0, 255), -1)\n",
    "        input_image = cv2.rectangle(\n",
    "            input_image, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)\n",
    "        cv2.putText(input_image, best_class_name + ': ' + confidence, (xmin + 5, ymin - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "    # If a display is available, show the image on which inference was performed\n",
    "    if 'DISPLAY' in os.environ:\n",
    "        cv2.imshow('NCS live inference', input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Unload the graph and close the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_ncs_device(device, graph, input_fifo, output_fifo):\n",
    "    output_fifo.destroy()\n",
    "    input_fifo.destroy()\n",
    "    graph.destroy()\n",
    "    device.close()\n",
    "    device.destroy()\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function (entry point for this script )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = open_ncs_device()\n",
    "    graph, input_fifo, output_fifo = load_graph(device)\n",
    "\n",
    "    # capture frames from the camera\n",
    "    while (camera.isOpened()):\n",
    "        ret, frame = camera.read()\n",
    "\n",
    "        img = pre_process_image(frame)\n",
    "        infer_image(graph, input_fifo, output_fifo, img, frame)\n",
    "\n",
    "        # Display the frame for 5ms, and close the window so that the next\n",
    "        # frame can be displayed. Close the window if 'q' or 'Q' is pressed.\n",
    "        if (cv2.waitKey(5) & 0xFF == ord('q')):\n",
    "            break\n",
    "\n",
    "    close_ncs_device(device, graph, input_fifo, output_fifo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define 'main' function as the entry point for this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-g GRAPH] [-D DIM [DIM ...]]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-46893de0-4f6e-4d53-9697-0e154363c1de.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pi/.virtualenvs/cv/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Detect objects on a LIVE camera feed using \\\n",
    "                         Intel Neural Compute Stick.\")\n",
    "\n",
    "    parser.add_argument('-g', '--graph', type=str,\n",
    "                        default='yolov2-tiny.graph',\n",
    "                        help=\"Absolute path to the neural network graph file.\")\n",
    "\n",
    "    parser.add_argument('-D', '--dim', type=int,\n",
    "                        nargs='+',\n",
    "                        default=[416, 416],\n",
    "                        help=\"Image dimensions. ex. -D 416 416\")\n",
    "\n",
    "    ARGS = parser.parse_args()\n",
    "\n",
    "    # Create a VideoCapture object\n",
    "    camera = cv2.VideoCapture(0)\n",
    "\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
